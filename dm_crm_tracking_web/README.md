**Description**

Generate aggregated data similar to Google Analytics from tracking

**Source**

The source of data is the parquet files generated by tracking

s3://bucket-cdr-main-{env}/datalake/tracking.db/tracking_web/src_raw_h/partition_date={date}/

**Destination**

csv files located in

s3://bucket-cdr-main-{env}/CRM/tracking/web/trafico_con_hotel/{date}
s3://bucet-cdr-main-{env}/CRM/tracking/web/trafico_sin_hotel/{date}

**Usage**

```
$./run-etl.sh [start_date] [environment] [end_date]
```


|parameter| default value | format |
|---|---|---|
| start_date | today | YYYY-MM-DD |
| environment | devel | {devel, live} |
| end_date | today | YYYY-MM-DD |


**Examples of execution**

* Most common parameters (no end_date)

```
$ ./run-etl.sh 2019-07-01 devel
2019-07-01
```

* Ascending interval

```
$ ./run-etl.sh 2019-07-01 devel 2019-07-04
```

This command executes the etl in this dates: 2019-07-01, 2019-07-02, 2019-07-03, 2019-07-04

* Descending interval

```
$ ./run-etl.sh 2019-07-01 devel 2019-06-29
```

This command executes the etl in this dates: 2019-07-01, 2019-06-30, 2019-06-29

* Equivalent to first example

```
$ ./run-etl.sh 2019-07-01 devel 2019-07-01
```

This command executes the etl in this dates: 2019-07-01

* All default values (Executed on 2019-07-31)

```
$ ./run-etl.sh
```

This command executes the etl in this dates: 2019-07-31

**Jira**


**Confluence**


**AirFlow**


**Known issues**

